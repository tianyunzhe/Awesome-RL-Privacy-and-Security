# Awesome-RL-Privacy-and-Security
 A curated list of papers and resources in RL privacy &amp; security.
## Contents
- [RL Security](#Awesome-RL-Security-Papers)
   - [Backdoor Attack](#backdoor-attack) 
   - [Backdoor Defense](#backdoor-defense) 
- [RL Privacy](#Awesome-RL-Privacy-Papers)
## Awesome-RL-Security-Papers

### Backdoor Attack

[2020-DAC] **TrojDRL: Evaluation of Backdoor Attacks on Deep Reinforcement Learning** [[Paper](https://ieeexplore.ieee.org/abstract/document/9218663)]

[2021-ICLR workshop] **Poisoning Deep Reinforcement Learning Agents with In-Distribution Triggers** [[Paper](https://arxiv.org/pdf/2106.07798.pdf)][[Code](https://github.com/trojai/trojai_rl)]

[2022-GLOBALCOM] **A Temporal-Pattern Backdoor Attack to Deep Reinforcement Learning** [[Paper](https://arxiv.org/pdf/2205.02589)][[Code](https://github.com/EboYu/DRLBackdoor)]

[2022-arXiv] **BAFFLE: Backdoor Attack in Offline Reinforcement Learning** [[Paper](https://arxiv.org/pdf/2210.04688.pdf)][[Code](https://github.com/2019ChenGong/Offline_RL_Poisoner/)]

[2024-AAAI] **BadRL: Sparse Targeted Backdoor Attack Against Reinforcement Learning** [[Paper](https://arxiv.org/pdf/2312.12585.pdf)][[Code](https://github.com/7777777cc/code)]


### Backdoor Defense



[2022-NeurIPS] **Provable Defense against Backdoor Policies in Reinforcement Learning** [[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/5e67e6a814526079ad8505bf6d926fb6-Paper-Conference.pdf)][[Code](https://github.com/skbharti/Provable-Defense-in-RL)]

[2023-arXiv] **Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning** [[Paper](https://arxiv.org/pdf/2304.00252.pdf)]

[2023-NeurIPS] **BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning** [[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/802e90325f4c8546e13e5763b2ecab88-Paper-Conference.pdf)]


## Awesome-RL-Privacy-Papers

